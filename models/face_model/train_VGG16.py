# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bi2STlJUu8oEPcvMMerGq_KuAKSKM0Hb

"""
# Mine
import numpy as np
import matplotlib.pyplot as plt
import pathlib
import inspect

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation



data_dir = r'C:\Users\sodaus\Desktop\data\ver3-2\LJW'
data_dir = pathlib.Path(data_dir)

BATCH_SIZE = 32
IMAGE_SIZE = 224

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    batch_size=BATCH_SIZE,
    # image_size=(IMAGE_SIZE, IMAGE_SIZE),
    shuffle=True,
    seed=112,
    validation_split=0.2,
    subset='training'
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    batch_size=BATCH_SIZE,
    # image_size=(IMAGE_SIZE, IMAGE_SIZE),
    shuffle=True,
    seed=112,
    validation_split=0.2,
    subset='validation'
)



add_noise = tf.keras.Sequential([
    tf.keras.layers.GaussianNoise(0.08)
])

def augment(image, label):
  image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
  image = (image / 255.0)
  image = tf.image.random_flip_left_right(image)
  image = tf.image.random_brightness(image, max_delta=0.15)
  image = tf.image.random_contrast(image, 0.7, 1.3)
  image = tf.image.random_hue(image, 0.05)  #  색조, 0 < x < 0.5
  image = tf.image.random_saturation(image, 0.7, 2.0)  # 채도
  image = add_noise(image, training=True)
  image = tf.clip_by_value(image, 0, 1)  # https://stackoverrun.com/ko/q/12304559
  return image, label

def resize_and_rescale(image, label):
  image = tf.cast(image, tf.float32)
  image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
  image = (image / 255.0)
  return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
train_ds = (
    train_ds
    .cache()
    .map(augment, num_parallel_calls=AUTOTUNE)
    .prefetch(AUTOTUNE)
)
val_ds = (
    val_ds
    .cache()
    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)
    .prefetch(AUTOTUNE)
)



from tensorflow.keras.applications import VGG16
base_model = VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet', pooling='avg')
fc6 = Dense(2048, activation='relu', name='fc6')(base_model.output)
fc6_drop = Dropout(0.5)(fc6)
fc7 = Dense(2048, activation='relu', name='fc7')(fc6_drop)
fc7_drop = Dropout(0.5)(fc7)
out = Dense(1, activation='sigmoid', name='fc8')(fc7_drop)
my_model = Model(inputs=base_model.input, outputs=out)

# freeze pretrained weights(layers) and train our own fc layers
for layer in my_model.layers:
  if 'fc' in layer.name:
    layer.trainable = True
  else:
    layer.trainable = False

my_model.summary()



LEARNING_RATE = 1e-3
my_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
                 loss=tf.losses.BinaryCrossentropy(),
                 metrics=['accuracy'])

cb_early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)
with tf.device('/device:GPU:0'):
  fit_history = my_model.fit(
      train_ds,
      # steps_per_epoch=len(train_ds),
      epochs=10,
      validation_data=val_ds,
      # validation_steps=len(val_ds),
      callbacks=[cb_early_stopper]
  )
  
# my_model.save('C:/Users/sodaus/Desktop/data/ver3-2/LJW_face_first_weights.h5')



import matplotlib.pyplot as plt
plt.subplot(2, 1, 1)
plt.plot(fit_history.history["accuracy"])
plt.plot(fit_history.history['val_accuracy'])
plt.title("Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend(["Accuracy","Val Accuracy"])
plt.subplot(2, 1, 2)
plt.plot(fit_history.history["loss"])
plt.plot(fit_history.history["val_loss"])
plt.title("Loss")
plt.xlabel("Epochs")
plt.ylabel("Binary CrossEntropy")
plt.legend(["Loss","Val Loss"])
plt.show()



from tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
    rescale=1./255,
)
test_generator = datagen.flow_from_directory(
    # directory=r'C:\Users\sodaus\Desktop\data\ver3-2\LJW_test',
    directory=r'C:\Users\sodaus\Desktop\data\ver3\predict_temp',
    # subset='training',
    target_size=(224, 224),
    # batch_size=8,
    shuffle=False,
    class_mode='binary'
    # seed=112
)
prediction = (my_model.predict(test_generator) >= 0.5).reshape(-1) - 0
result = (prediction == test_generator[0][1])
print(result, '\naccuracy: ', sum(result)/len(result))